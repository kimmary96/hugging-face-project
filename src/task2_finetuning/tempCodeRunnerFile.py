from unsloth import FastLanguageModel
import torch
from datasets import load_dataset
from trl import SFTTrainer
from trl.trainer.sft_config import SFTConfig

# ==========================================
# 1. ì„¤ì • (RTX 4070 Ti S ë§ì¶¤í˜•)
# ==========================================
# í•™ìŠµ íƒ€ê²Ÿ: 16GB VRAMì—ì„œ í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¥ ë˜‘ë˜‘í•œ ëª¨ë¸ (Qwen 3 4B)
# â€» 14BëŠ” í•™ìŠµ ì‹œ OOM ë°œìƒí•˜ë¯€ë¡œ 4Bë¥¼ Studentë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
MODEL_NAME = "unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit" 
OUTPUT_DIR = "outputs_checkpoint"
DATA_FILE = "cleaned_train_data.jsonl" # ë°©ê¸ˆ ì •ì œí•œ íŒŒì¼

# 4070 TiëŠ” bfloat16ì„ ì§€ì›í•˜ë¯€ë¡œ Trueë¡œ ì„¤ì • (ì†ë„/ì„±ëŠ¥ í–¥ìƒ)
USE_BFLOAT16 = True 
MAX_SEQ_LENGTH = 2048 # 7B ëª¨ë¸ì€ 16GBì—ì„œ 2048 ê¸¸ì´ë„ ë„‰ë„‰í•¨

# ==========================================
# 2. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
# ==========================================
print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘... ({MODEL_NAME})")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = MODEL_NAME,
    max_seq_length = MAX_SEQ_LENGTH,
    dtype = None, # Auto detection (bf16)
    load_in_4bit = True,
)

# LoRA ì–´ëŒ‘í„° ì„¤ì • (ëª¨ë¸ì˜ ì „ì²´ë¥¼ íŠœë‹í•˜ëŠ” ëŒ€ì‹  ì¼ë¶€ë§Œ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµ)
model = FastLanguageModel.get_peft_model(
    model,
    r = 16, # Rank: ë†’ì„ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§€ì§€ë§Œ ë©”ëª¨ë¦¬ ë” ì”€ (16 ì¶”ì²œ)
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 16,
    lora_dropout = 0, 
    bias = "none",   
    use_gradient_checkpointing = "unsloth", # ë©”ëª¨ë¦¬ ì ˆì•½ í•µì‹¬ ê¸°ìˆ 
    random_state = 3407,
)

# ==========================================
# 3. ë°ì´í„°ì…‹ ë¡œë“œ ë° í¬ë§·íŒ…
# ==========================================
print("ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
dataset = load_dataset("json", data_files=DATA_FILE, split="train")

# Alpaca ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ í¬ë§·
alpaca_prompt = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}"""

EOS_TOKEN = tokenizer.eos_token 

def formatting_prompts_func(examples):
    instructions = examples["instruction"]
    inputs       = examples["input"]
    outputs      = examples["output"]
    texts = []
    for instruction, input, output in zip(instructions, inputs, outputs):
        # EOS í† í°ì„ ë¶™ì—¬ì•¼ ëª¨ë¸ì´ ìƒì„±ì„ ë©ˆì¶”ëŠ” ë²•ì„ ë°°ì›€
        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN
        texts.append(text)
    return { "text" : texts, }

dataset = dataset.map(formatting_prompts_func, batched = True)

# ==========================================
# 4. íŠ¸ë ˆì´ë„ˆ ì„¤ì • (Hyperparameters)
# ==========================================
trainer = SFTTrainer(
    model = model,
    tokenizer = tokenizer,
    train_dataset = dataset,
    args = SFTConfig(
        dataset_text_field = "text",
        max_length = MAX_SEQ_LENGTH,
        dataset_num_proc = 2,
        packing = False,
        per_device_train_batch_size = 4, # 16GB VRAM ê¸°ì¤€ 4~8 ê°€ëŠ¥
        gradient_accumulation_steps = 4, # 4 * 4 = ì‹¤ì œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ 16 íš¨ê³¼
        warmup_steps = 10,
        max_steps = 100, # ë°ì´í„° 132ê°œì´ë¯€ë¡œ 100 ìŠ¤í…ì´ë©´ ì¶©ë¶„íˆ í•™ìŠµë¨
        learning_rate = 2e-4, # í•™ìŠµë¥  (LoRA í‘œì¤€)
        fp16 = not USE_BFLOAT16,
        bf16 = USE_BFLOAT16,
        logging_steps = 1, # ë§¤ ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
        optim = "adamw_8bit", # ë©”ëª¨ë¦¬ ì ˆì•½í˜• ì˜µí‹°ë§ˆì´ì €
        weight_decay = 0.01,
        lr_scheduler_type = "linear",
        seed = 3407,
        output_dir = OUTPUT_DIR,
        report_to = "none", # ì™„ë“œë¹„(WandB) ì‚¬ìš© ì•ˆí•¨
    ),
)

# ==========================================
# 5. í•™ìŠµ ì‹¤í–‰
# ==========================================
print("ğŸš€ í•™ìŠµ ì‹œì‘! (ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5~10ë¶„)")
trainer_stats = trainer.train()

print("ğŸ‰ í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ ì¤‘...")
model.save_pretrained(OUTPUT_DIR) # LoRA ì–´ëŒ‘í„°ë§Œ ì €ì¥ë¨ (ìš©ëŸ‰ ì‘ìŒ)
tokenizer.save_pretrained(OUTPUT_DIR)
print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {OUTPUT_DIR}")