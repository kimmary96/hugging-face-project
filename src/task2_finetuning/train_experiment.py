import os
from unsloth import FastLanguageModel
from datasets import load_dataset
from trl.trainer.sft_trainer import SFTTrainer
from trl.trainer.sft_config import SFTConfig
import matplotlib.pyplot as plt
import numpy as np

# ==========================================
# ì‹¤í—˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ì´ ë¶€ë¶„ì„ ë°”ê¿”ê°€ë©° ì‹¤í—˜í•˜ì„¸ìš”)
# ==========================================
EXP_NAME = "Exp6_Dataset500"  # ì‹¤í—˜ ì´ë¦„ (ì €ì¥ í´ë”ëª…)
LEARNING_RATE = 2e-4           # í•™ìŠµë¥  (2e-4, 2e-5, 2e-3 ë“± ì‹¤í—˜)
NUM_TRAIN_EPOCHS = 5          # ì—í­ (1, 5, 10 ë“± ì‹¤í—˜)
LORA_RANK = 64                 # LoRA Rank (8, 16, 64 ë“± ì‹¤í—˜)

# ==========================================
# ì„¤ì •
# ==========================================
MODEL_NAME = "unsloth/Qwen3-4B-Instruct-2507-unsloth-bnb-4bit"
DATA_FILE = "src/task2_finetuning/cleaned_train_data.jsonl"
OUTPUT_DIR = f"outputs_experiments/{EXP_NAME}"
MAX_SEQ_LENGTH = 2048

ALPACA_PROMPT = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}"""


def main():
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # ==========================================
    # 1. ëª¨ë¸ ë¡œë“œ
    # ==========================================
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘... ({MODEL_NAME})")
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=MODEL_NAME,
        max_seq_length=MAX_SEQ_LENGTH,
        dtype=None,
        load_in_4bit=True,
    )

    model = FastLanguageModel.get_peft_model(
        model,
        r=LORA_RANK,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                        "gate_proj", "up_proj", "down_proj"],
        lora_alpha=16,
        lora_dropout=0,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=3407,
    )

    # ==========================================
    # 2. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í• 
    # ==========================================
    print("ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    dataset = load_dataset("json", data_files=DATA_FILE, split="train")
    dataset = dataset.train_test_split(test_size=0.2, seed=42)
    train_dataset = dataset["train"]
    eval_dataset = dataset["test"]

    print(f"ğŸ“Š ë°ì´í„° ë¶„í• : Train({len(train_dataset)}ê°œ) / Eval({len(eval_dataset)}ê°œ)")

    eos_token = tokenizer.eos_token

    def formatting_prompts_func(examples):
        texts = []
        for instruction, inp, output in zip(
            examples["instruction"], examples["input"], examples["output"]
        ):
            text = ALPACA_PROMPT.format(instruction, inp, output) + eos_token
            texts.append(text)
        return {"text": texts}

    train_dataset = train_dataset.map(formatting_prompts_func, batched=True)
    eval_dataset = eval_dataset.map(formatting_prompts_func, batched=True)

    # ==========================================
    # 3. íŠ¸ë ˆì´ë„ˆ ì„¤ì •
    # ==========================================
    trainer = SFTTrainer(
        model=model,
        processing_class=tokenizer,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        args=SFTConfig(
            dataset_text_field="text",
            max_length=MAX_SEQ_LENGTH,
            dataset_num_proc=1,
            packing=False,
            per_device_train_batch_size=4,
            per_device_eval_batch_size=4,
            gradient_accumulation_steps=4,
            num_train_epochs=NUM_TRAIN_EPOCHS,
            learning_rate=LEARNING_RATE,
            fp16=False,
            bf16=True,
            optim="adamw_8bit",
            weight_decay=0.01,
            lr_scheduler_type="linear",
            seed=3407,
            output_dir=OUTPUT_DIR,
            eval_strategy="steps",
            eval_steps=5,
            logging_steps=5,
            save_strategy="steps",
            save_steps=20,
            save_total_limit=2,
            load_best_model_at_end=True,
            report_to="none",
        ),
    )

    # ==========================================
    # 4. í•™ìŠµ ì‹¤í–‰
    # ==========================================
    print(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {EXP_NAME} (LR={LEARNING_RATE}, Epoch={NUM_TRAIN_EPOCHS}, Rank={LORA_RANK})")
    trainer.train()

    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ ì¤‘...")
    model.save_pretrained(OUTPUT_DIR)
    tokenizer.save_pretrained(OUTPUT_DIR)
    print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {OUTPUT_DIR}")

    # ==========================================
    # 5. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
    # ==========================================
    print("ğŸ“Š ê·¸ë˜í”„ ê·¸ë¦¬ëŠ” ì¤‘...")

        # 1. ë¡œê·¸ ë°ì´í„° ì¶”ì¶œ (Steps ëŒ€ì‹  Epoch ì‚¬ìš©)
    history = trainer.state.log_history
    train_loss = []
    train_epochs = []
    eval_loss = []
    eval_epochs = []

    for entry in history:
        if 'loss' in entry: # Training Log
            train_loss.append(entry['loss'])
            train_epochs.append(entry['epoch'])
        elif 'eval_loss' in entry: # Validation Log
            eval_loss.append(entry['eval_loss'])
            eval_epochs.append(entry['epoch'])

    # 2. ìµœì ì (Saturation Point) ìë™ ê³„ì‚°
    # Validation Lossê°€ ê°€ì¥ ë‚®ì€ ì§€ì ì„ ì°¾ìŠµë‹ˆë‹¤.
    if len(eval_loss) > 0:
        min_loss_idx = np.argmin(eval_loss)
        min_val_loss = eval_loss[min_loss_idx]
        best_epoch = eval_epochs[min_loss_idx]
    else:
        # í˜¹ì‹œ Eval ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ì²˜ë¦¬
        best_epoch = 0
        min_val_loss = 0

    # 3. ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
    plt.figure(figsize=(12, 7)) # í¬ê¸°ë¥¼ ì¡°ê¸ˆ ë” í‚¤ì›€

    # Train Loss (íŒŒë€ìƒ‰ ì‹¤ì„  + ì›í˜• ë§ˆì»¤)
    plt.plot(train_epochs, train_loss, 
            label='Training Loss', 
            marker='o', color='blue', linestyle='-', linewidth=1.5, markersize=5)

    # Eval Loss (ë¹¨ê°„ìƒ‰ ì ì„  + X ë§ˆì»¤)
    plt.plot(eval_epochs, eval_loss, 
            label='Validation Loss', 
            marker='x', color='red', linestyle='--', linewidth=2, markersize=6)

    # 4. ê¾¸ë¯¸ê¸° ìš”ì†Œ (Grid, Title)
    plt.title(f'Learning Curve: {EXP_NAME}', fontsize=14, pad=15)
    plt.xlabel('Epochs', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.legend(fontsize=11)
    plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)

    # 5. ìµœì ì (Optimal Point) ì‹œê°í™”
    if len(eval_loss) > 0:
        plt.axvline(x=best_epoch, color='green', linestyle=':', linewidth=2, label='Optimal Point')
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ìë™ ì¡°ì • (ê·¸ë˜í”„ ì¤‘ê°„ ë†’ì´)
        text_y_pos = (max(train_loss) + min(train_loss)) / 2
        
        plt.text(best_epoch + 0.1, text_y_pos, 
                f'Saturation Point\n(Epoch {best_epoch:.2f}, Loss {min_val_loss:.4f})', 
                color='green', fontweight='bold', fontsize=10,
                bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))

    plt.tight_layout()

    # í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ ê³ ìœ  íŒŒì¼ëª…
    graph_filename = f"loss_LR{LEARNING_RATE}_EP{NUM_TRAIN_EPOCHS}_R{LORA_RANK}.png"
    graph_path = os.path.join(OUTPUT_DIR, graph_filename)
    plt.savefig(graph_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“ˆ ê·¸ë˜í”„ ì €ì¥ë¨: {graph_path}")
    plt.close()


if __name__ == '__main__':
    main()
